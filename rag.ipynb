{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d0f568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langgraph in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (1.2.1)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.1-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-ollama) (0.6.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Downloading faiss_cpu-1.13.1-cp310-cp310-win_amd64.whl (18.8 MB)\n",
      "   ---------------------------------------- 0.0/18.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.8 MB 1.4 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.8/18.8 MB 1.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.3/18.8 MB 1.9 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 2.1/18.8 MB 2.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.6/18.8 MB 2.3 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 2.9/18.8 MB 2.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 3.4/18.8 MB 2.3 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 3.9/18.8 MB 2.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 4.5/18.8 MB 2.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.7/18.8 MB 2.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 5.0/18.8 MB 2.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 5.0/18.8 MB 2.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 5.2/18.8 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 5.2/18.8 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 5.5/18.8 MB 1.7 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 5.5/18.8 MB 1.7 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 5.8/18.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 5.8/18.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 6.0/18.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 6.3/18.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 6.3/18.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 6.6/18.8 MB 1.4 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 6.8/18.8 MB 1.4 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 6.8/18.8 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 7.1/18.8 MB 1.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 7.1/18.8 MB 1.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 7.3/18.8 MB 1.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 7.3/18.8 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 7.6/18.8 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 7.6/18.8 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 7.6/18.8 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 7.9/18.8 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 7.9/18.8 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 8.1/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 8.4/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 8.4/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 8.4/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 8.7/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 8.7/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 8.7/18.8 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 8.9/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 9.2/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 9.2/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 9.4/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 9.4/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 9.7/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 9.7/18.8 MB 1.0 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 10.0/18.8 MB 980.7 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 10.0/18.8 MB 980.7 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 10.0/18.8 MB 980.7 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 10.2/18.8 MB 958.8 kB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 10.5/18.8 MB 958.0 kB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 10.5/18.8 MB 958.0 kB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 10.7/18.8 MB 954.6 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 11.0/18.8 MB 955.4 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 11.3/18.8 MB 952.3 kB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 11.3/18.8 MB 952.3 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 11.5/18.8 MB 944.3 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 11.5/18.8 MB 944.3 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 11.8/18.8 MB 933.3 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 11.8/18.8 MB 933.3 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 12.1/18.8 MB 930.9 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 12.1/18.8 MB 930.9 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 12.3/18.8 MB 917.7 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 12.3/18.8 MB 917.7 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 12.6/18.8 MB 916.9 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 12.8/18.8 MB 913.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 12.8/18.8 MB 913.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 13.1/18.8 MB 912.4 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 13.1/18.8 MB 912.4 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 13.4/18.8 MB 906.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 13.6/18.8 MB 907.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 13.6/18.8 MB 907.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 13.9/18.8 MB 898.5 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 14.2/18.8 MB 901.8 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 14.4/18.8 MB 904.2 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 14.4/18.8 MB 904.2 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 14.7/18.8 MB 902.9 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 14.9/18.8 MB 904.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 15.2/18.8 MB 909.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 15.5/18.8 MB 912.0 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 15.7/18.8 MB 914.9 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 15.7/18.8 MB 914.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 16.0/18.8 MB 912.7 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 16.3/18.8 MB 911.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 16.5/18.8 MB 918.1 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 17.0/18.8 MB 932.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 17.6/18.8 MB 950.5 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 18.1/18.8 MB 967.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  18.4/18.8 MB 974.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.8/18.8 MB 987.1 kB/s  0:00:18\n",
      "Downloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
      "Installing collected packages: pypdf, faiss-cpu\n",
      "\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   -------------------- ------------------- 1/2 [faiss-cpu]\n",
      "   -------------------- ------------------- 1/2 [faiss-cpu]\n",
      "   -------------------- ------------------- 1/2 [faiss-cpu]\n",
      "   -------------------- ------------------- 1/2 [faiss-cpu]\n",
      "   -------------------- ------------------- 1/2 [faiss-cpu]\n",
      "   -------------------- ------------------- 1/2 [faiss-cpu]\n",
      "   ---------------------------------------- 2/2 [faiss-cpu]\n",
      "\n",
      "Successfully installed faiss-cpu-1.13.1 pypdf-6.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community langgraph python-dotenv faiss-cpu pypdf langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7b5473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-text-splitters) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\loq\\downloads\\chatbot_using_langgraph\\chatbotenv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-text-splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd362624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (optional)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# PDF Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Text Splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vector Store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Embeddings (Local)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# LLM (Local Ollama)\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Tools\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "# Prebuilt Tool Node\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# For type-safe state definition\n",
    "from typing import TypedDict, Annotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7d0762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5c1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2:3b\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71273370",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"intro-to-ml.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6f8b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ef1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1caf941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2611c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2be5cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1fdd11ce260>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95a44c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49acedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_tool(query):\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the pdf document.\n",
    "    Use this tool when the user asks factual / conceptual questions\n",
    "    that might be answered from the stored documents.\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "\n",
    "    context = [doc.page_content for doc in result]\n",
    "    metadata = [doc.metadata for doc in result]\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'context': context,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2275e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [rag_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25d2a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa95f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf5972e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7782d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node('chat_node', chat_node)\n",
    "graph.add_node('tools', tool_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_conditional_edges('chat_node', tools_condition)\n",
    "graph.add_edge('tools', 'chat_node')\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e432eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chatbot.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    \"Using the pdf notes, explain how to find the ideal value of K in KNN\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5749541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ideal value of K in KNN (k-nearest neighbors) depends on the specific problem and dataset being used. However, there are some general guidelines for choosing the optimal value of K.\n",
      "\n",
      "One common approach is to use cross-validation to evaluate the performance of different values of K and select the one that results in the best accuracy or other metric of interest.\n",
      "\n",
      "Another approach is to use a grid search over a range of possible values of K, such as 1 to 10, and evaluate the performance of each value using metrics such as accuracy, precision, recall, F1 score, etc.\n",
      "\n",
      "In addition, some algorithms for choosing the optimal value of K include:\n",
      "\n",
      "* The \"rule of thumb\" approach, which recommends selecting K based on the number of data points in the dataset. For example, if there are N data points, then K should be set to around âˆšN.\n",
      "* The \"Leave-One-Out\" (LOO) cross-validation method, which involves training and testing the model on each individual data point in turn, and evaluating the performance of the model for each value of K.\n",
      "* The \"k-fold\" cross-validation method, which involves splitting the dataset into k folds, training and testing the model on each fold in turn, and evaluating the performance of the model for each value of K.\n",
      "\n",
      "In general, it's a good idea to use a combination of these approaches to find the optimal value of K for your specific problem and dataset.\n",
      "\n",
      "Based on the provided PDF notes, here is an example of how to use cross-validation to evaluate the performance of different values of K:\n",
      "```\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.model_selection import LeaveOneOut\n",
      "\n",
      "# Load the dataset\n",
      "X_train, X_test, y_train, y_test = ...\n",
      "\n",
      "# Initialize the model with different values of K\n",
      "k_values = [1, 3, 5, 7, 9]\n",
      "models = []\n",
      "for k in k_values:\n",
      "    model = KNeighborsClassifier(n_neighbors=k)\n",
      "    models.append(model)\n",
      "\n",
      "# Perform cross-validation for each value of K\n",
      "results = []\n",
      "for model in models:\n",
      "    loo = LeaveOneOut()\n",
      "    scores = []\n",
      "    for train_index, test_index in loo.split(X_train):\n",
      "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
      "        y_train_fold, y_test_fold = y_train[train_index], y_test[test_index]\n",
      "        model.fit(X_train_fold, y_train_fold)\n",
      "        scores.append(model.score(X_test_fold, y_test_fold))\n",
      "    results.append(np.mean(scores))\n",
      "\n",
      "# Print the results\n",
      "print(\"K\\tAccuracy\")\n",
      "for k, accuracy in zip(k_values, results):\n",
      "    print(f\"{k}\\t{accuracy:.3f}\")\n",
      "```\n",
      "This code uses cross-validation to evaluate the performance of different values of K for a KNN model, and prints the accuracy for each value of K.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8d1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
